{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e75bb9",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Write a python program to display all the header tags from wikipedia.org​. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da53e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "titles = soup.find_all(['h1', 'h2','h3'])\n",
    "print('List of all the header tags :', *titles, sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f98a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330d18de",
   "metadata": {},
   "source": [
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  bs4 import BeautifulSoup\n",
    "import  requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/list/ls020728848/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24282524",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = []\n",
    "rating = []\n",
    "year_release = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = soup.findAll('div', attrs= {'class': \"lister-item mode-detail\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in movie_data: \n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year_of_release = store.h3.find('span', class_ = \"lister-item-index unbold text-primary\").text.replace('(', '').replace(')', '')\n",
    "    year_release.append(year_of_release)\n",
    "    \n",
    "    rate = store.find('div', class_ =  \"ipl-rating-star\").text.replace('\\n', '')\n",
    "    rating.append(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64632fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating data frame to show the movie names along with rating and year of release. \n",
    "\n",
    "movie_DF = pd.DataFrame({'Name of Movie': movie_name, 'Year of release': year_release, 'Rating': rating})\n",
    "movie_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38cc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c996a405",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c980f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = []\n",
    "rating = []\n",
    "year_release = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = soup.findAll('div', attrs= {'class': \"lister-item mode-detail\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in movie_data: \n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year_of_release = store.h3.find('span', class_ = \"lister-item-year text-muted unbold\").text.replace('(', '').replace(')', '')\n",
    "    year_release.append(year_of_release)\n",
    "    \n",
    "    rate = store.find('div', class_ = \"ipl-rating-star\").text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating data frame to show the movie names along with rating and year of release. \n",
    "\n",
    "movie_DF = pd.DataFrame({'Name of Movie': movie_name, 'Rating': rating, \"Year of Release\": year_release})\n",
    "movie_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32872da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a747313",
   "metadata": {},
   "source": [
    "## 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  bs4 import BeautifulSoup\n",
    "import  requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://meesho.com/bags-ladies/pl/p7vbp\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = []\n",
    "price = []\n",
    "discount = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('div', class_= \"Card__BaseCard-sc-b3n78k-0 dUNFgg NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS NewProductCard__DetailCard_Desktop-sc-j0e7tu-2 fqvaeS\"):\n",
    "    product_name.append(i.p.text)\n",
    "    \n",
    "for i in soup.find_all('div', class_= \"Card__BaseCard-sc-b3n78k-0 iLPHgK NewProductCard__PriceRow-sc-j0e7tu-5 eyya-Dr NewProductCard__PriceRow-sc-j0e7tu-5 eyya-Dr\"):\n",
    "    price.append(i.h5.text.replace('\\n',''))\n",
    "    \n",
    "for i in soup.find_all('div', class_= \"Card__BaseCard-sc-b3n78k-0 iJCKg NewProductCard__DiscountRow-sc-j0e7tu-15 kUcVjG NewProductCard__DiscountRow-sc-j0e7tu-15 kUcVjG\"):\n",
    "    discount.append(i.text.replace('\\n',''))\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bc5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messo_df = pd.DataFrame({ 'Product': product_name, 'Price': price, 'Discounts': discount })\n",
    "messo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "259278b6",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8149a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get response. \n",
    "page = requests.get('https://www.icc-cricket.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "\n",
    "##Top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853df2e",
   "metadata": {},
   "source": [
    "#### 5th (B) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5275b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d92871",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "\n",
    "## Top 10 ODI Batsmen along with the records of their team and rating\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c12295",
   "metadata": {},
   "source": [
    "##### 5th (c) Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86725217",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "    \n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "      \n",
    "## Top 10 ODI bowlers along with the records of their team and rating.\n",
    "data.head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdff2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6d437c",
   "metadata": {},
   "source": [
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf96b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d663bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e86a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "\n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "\n",
    "\n",
    "##  Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade11f4",
   "metadata": {},
   "source": [
    "#### (B) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "\n",
    "\n",
    "## Top 10 women’s ODI Batting players along with the records of their team and rating..\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a5b58",
   "metadata": {},
   "source": [
    "#### 6th (C) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37487693",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "html_table = soup.find(\"table\", {\"class\": \"table\"})\n",
    "data = pd.read_html(html_table.prettify())[0]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e368a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f74aee",
   "metadata": {},
   "source": [
    "## 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e12b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://coreyms.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d810c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://coreyms.com/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ba0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = []\n",
    "content = []\n",
    "time = []\n",
    "\n",
    "\n",
    "## scraping imp data \n",
    "\n",
    "for i in soup.find_all(\"h2\", class_= \"entry-title\" ):\n",
    "    heading.append(i.text)\n",
    "\n",
    "for i in soup.find_all('div', class_= \"entry-content\" ):\n",
    "    content.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('time', class_=\"entry-time\"):\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79370f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping URLS. \n",
    "\n",
    "youtube = []\n",
    "links = []\n",
    "for i in soup.find_all('div', class_= \"entry-content\" ):\n",
    "    youtube.append(i.iframe)\n",
    "    \n",
    "youtube\n",
    "\n",
    "for i in youtube:\n",
    "    try:\n",
    "        links.append(i['src'])\n",
    "    except:\n",
    "        links.append('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1619d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e725aab72c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## creating dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcoreym_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Heading'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mheading\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Content'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Time'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Youtube Link'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## creating dataframe \n",
    "coreym_df = pd.DataFrame({'Heading': heading, 'Content': content, 'Time': time, 'Youtube Link': links})\n",
    "coreym_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadfa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857acd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce087ca0",
   "metadata": {},
   "source": [
    "## 8. Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa81494",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.nobroker.in/')\n",
    "\n",
    "response = requests.get(\"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&type=BHK1&propertyAge=0&city=bangalore&locality=Indiranagar,&locality=Jayanagar,&locality=Rajajinagar\")\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee93a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_title = []\n",
    "location = []\n",
    "area = []\n",
    "emi = []\n",
    "price = []\n",
    "\n",
    "# Extracting details from website. \n",
    "\n",
    "for i in soup.find_all('h2', class_= \"heading-6 flex items-center font-semi-bold m-0\"):\n",
    "    house_title.append(i.text)\n",
    "for i in soup.find_all(\"div\", class_= \"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "store = []    \n",
    "for i in soup.find_all(\"div\", class_=\"font-semi-bold heading-6\"):\n",
    "    store.append(i.text)\n",
    "    \n",
    "area_price_details = store[0:]\n",
    "\n",
    "area = store[0::3]\n",
    "\n",
    "emi = store[1::3]\n",
    "\n",
    "price = store[2::3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16082a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Dataframe.. \n",
    "\n",
    "broker_df = pd.DataFrame({'House Title': house_title, 'House Location': location, 'Area': area, 'EMI Amount': emi, 'Price': price})\n",
    "broker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326805a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d62aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "756c5fb3",
   "metadata": {},
   "source": [
    "## 9 Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7251f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "cuisine = []\n",
    "location = []\n",
    "rating = []\n",
    "image_url = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b85fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting imp Data. \n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):  \n",
    "    name.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    image_url.append(i['data-src'])\n",
    "    \n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.string)\n",
    "    \n",
    "for i in soup.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.a.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63944c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Dataframe to show the restaurant name, Cuisine, Location, rating and Image URL. \n",
    "\n",
    "dine_DF = pd.DataFrame({'Restaurant name': name, 'Cuisine': cuisine, 'Location': location, 'Rating': rating, 'Image URL': image_url})\n",
    "dine_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19933753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f7b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e4b524",
   "metadata": {},
   "source": [
    "## 10 Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all the imp libraries.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://www.bewakoof.com/women-tshirts?ga_q=tshirts\")\n",
    "page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037581e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f71be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "price = []\n",
    "url = []\n",
    "\n",
    "for i in soup.find_all('div', class_= \"productCardDetail\" ):\n",
    "    name.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('span', class_=\"discountedPriceText\" ):\n",
    "    price.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('img', class_=\"productImgTag\" ):\n",
    "    url.append(i['src'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating data frame for product name, price and Image URl.\n",
    "\n",
    "product_df = pd.DataFrame({'Product name': name, 'Price': price, 'Image_url': url})\n",
    "product_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cb543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbcc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b51249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a01e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e2e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d65a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7b6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786b508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d64860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a21ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716d86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e193bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1d939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd86ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5308cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0f571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa484d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0608c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c6fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb19a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b72510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aae69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f829b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630922ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ac98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576191bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df3ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbbc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c064f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ad24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c756f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9456a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11c22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b884e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ae839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09e9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac966644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5b3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d87137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe563ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f252a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08682c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8820463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd75c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86077e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b450fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cf886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ab96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45638c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ceeade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c41388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea252ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76853cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba6b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
